
- [x] 졸업요건 관련해서 사무실 연락하기 ( 10 - 17 )
	- [ ] 융선 변경 관련해서 직접 연락드리기
- [ ] 지난주 transformer part 복습하고 (7/23 화요일 진행)
- [ ] 받은 Dataset 가지고 어떤 목적으로 어떻게 접근할지 계속 고민하기
	- [ ] input - ouput 토대로
	- [ ] Level을 높인다고 생각하고! 조급하지 않고 학습하기
	- [ ] Model 이 생각보다 잘 나왔다?(Regression 관련 결과가 좋음)
		- [x] 결과 더 제대로 봐야 할 듯. 단순히 그래프 상으로 비슷해보이네? 이런 접근은 좋지 못함. 통계를 어떻게 바라볼지 더 생각해보기
		- [x] Cross_Validation 모델 적용해서 생각해보기
			- [ ] 일단 적당하게 통계치를 만들어두고 그리고 나서 paper 기반의 network 생각해보기
				- [ ] **24일자 해야할일 만들고 진행할 것 
			- [ ] 정규화 좌표가 아니라 절대 좌표로 구해서 MAE 파악해보기
				- [ ] Regression 기반의 evaluation을 어떻게 접근할 지 생각해보기
		- [ ] Classification - Contrastive learning을 어떻게 엮어볼지 생각해보기
		- [ ] Regression에서는 단순한 MLP 파일도 동작하는데 문제가 없음
- [ ] 연관 paper 읽는 습관 들이기(매일 하루에 하나씩 읽을 수 있도록 집중하기)

##### 07.23 

이제서야 모델에 조금조금씩 어떤 변화를 가할지가 보인다. 

##### 07.24

- [ ] output (6개의 2차원 좌표 출력하는 형태로 수정)
	- [ ] 기존에는 12차원으로 변환해서 예측
	- [ ] 공간성을 상실하지 않은채로 output을 도출하는 방향으로 수정 
- [ ] Regression 관련 평가지표 다양하게 적용해보는 연습 
- [ ] log library 활용해서 시간 단축 



내가 발견하는 문제에서 발견되는 특유한 특이한 문제를 끄집어 내야돼
3D pose estimation 좋으니까 공통된 스페이스에 올리는 방법을 찾아야 돼(비전스럽게)
2d 영상으로부터 3D 포즈를 estimation + depth estimation



##### 07.25 

- [ ] 실제로 좌표 결과를 토대로 넣어보는 연습도 해볼 것 
	- [ ]  Cross-validation 진행 중 - fold당 epoch 100
		- [ ] 마지막 폴드 상에서의 테스트 중 첫번째 이미지를 샘플로 좌표를 따라 그려본 결과... 잘 안 맞음. 나머지 이미지들도 모두 돌려서 확인해보고 잘 안 맞는지 직접 눈으로 확인할 예정임
	- [ ] 각 이미지 별 properties 정보는 metadata로 따로 유지하고 있지 않음. 따라서 일단 10개만 추출해보고 직접 정보 확인하고 수동으로 width, height 기입해서 어느 정도로 값을 예측하고 있는지 확인할 예정
	- [ ] padded images로 결과 확인 - 학습 못함. R2 점수가 나빴던게 맞았다. 
- [ ] 교수님 면담 내용 다시 한 번 듣고 정리하기
	- [ ] common coordinate system에 올리는 방법에 대해서
	- [ ] camera parameters estimation



##### 생각해야 하는 것들을 정리해보자면.

- [ ] 이전 모델은 제대로 학습이 되지 못한 걸로. 
	- [ ] R2 점수는 0.03 실제 좌표축에서 출력했을 때도 문제가 많았음 
	- [ ] 압력 데이터. . 이것도 더 생각해봐야 한다.


##### 교수님 면담 관련 내용 정리

- 영상이 있으면 사람을 가까이에서 찍을 수도 있고 멀리 이렇게 찍을 수도 있다. 
- 어깨부터 돌린다고 생각하면,, 이 서로 다른 2가지 형태를 같은 space에 올렸어. 이사람도 저사람도 같이 공통으로 올라갈 수 있는 공간을 이야기 하는거지. zoom-in, zoom-out 형태로 적용을 했던 거였어. 포즈만 잘 잡히도록 같은 space에 올리는거지 (normalized 된 형태라고 생각을 했을 때)
- 상체까지 pose 좌표가 제대로 반영되어 있어야 해. 반영만 되면 큰 문제는 없어 여기에서 fancy한 방법이 필요한 셈이지. 
	- 사진에서 pose 좌표만 필요한 상황이다. 상반신까지의 pose 다르게 말하면 관절좌표만 제대로 반영되어 있다면 문제 없다. 서로 다른 거리, 서로 다른 각도에서 바라봤는데 이러한 coordinate을 어떻게 하나의 공간으로 올릴거냐!가 주요 관건이 되겠다. 


카메라 파라미터 - 물체와 어느정도 떨어지고 있는지, 어떤 각도로 바라보고 있는지를 말하는 거든. 말하는 거거든

카메라 파라미터를 추적하는 기술도 있기는 함. 영상을 보고 depth estimation 하는 것도 있고.. 근데 이런 부분을 어떻게 fancy하게 가지고 갈꺼냐 이게 사실 논문의 첫 단추를 끼운다고 생각을 해. 

현재 우리가 사용하는 것은 monocular, 3차원으로 보내고 싶으면 streo 타입으로 적용해야 하는데.. 이게 안되면 그냥 2차원으로 올려야 해. 2차원으로 이게 충분할 건지,, 이런 것들도 같이 고민을 해주면 좋지 

너무 방법이 없다 싶으면 camer parameters estimation을 적용해도 된다. 


###### ==Camera calibration 

2D 이미지에서 3D 세계의 정보를 정확하게 복원할 수 있다. 



###### ==depth estimation

> depth 그리고 camera parameters 정보를 반영할 수 있다면 더 원활하게 보정이 가능하다.

원근감 처리를 위한 방식을 생각하던 중에 depth estimatino이 있어서 참고



######  Blazepose(Pre-trained model) output


![[Pasted image 20240726135117.png]]


![[Pasted image 20240726135125.png]]

